{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1576e777c47532ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Learning Sparse Reward Models\n",
    "\n",
    "We consider the case of learning the reward function of the pendulum. In particular, we aim to learn the reward function $R:\\mathcal{S}\\times \\mathcal{A}\\rightarrow \\mathbb{R}$, predicting the reward $\\hat{r}_t$ from the current state $\\mathbf{s}_t$ and action $\\mathbf{a}_t$: $$\\hat{r}_t=R(\\mathbf{s}_t, \\mathbf{a}_t).$$ We will approximate $R(\\mathbf{s}_t, \\mathbf{a}_t)$ using:\n",
    "* a fully-connected neural network (fcnn_model),\n",
    "* a fully-connected neural network sparsified by the L$_0$ regularization (sparsefcnn_model), and\n",
    "* a SINDy-like architecture again sparsified by the L$_0$ regularization (l0sindy_model)."
   ],
   "id": "203b0ba5353dd2c7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T12:23:33.924092Z",
     "start_time": "2024-06-19T12:23:33.921203Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "from utils.replay_buffer import ReplayBuffer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds\n",
    "seed = 23524\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We first create a training set composed of 1000 episodes of 200 steps each. The actions are sampled from a random policy.",
   "id": "285aa8507a1b279d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "render = False\n",
    "if render:\n",
    "    env = gym.make('Pendulum-v1', g=9.81, render_mode=\"human\")\n",
    "else:\n",
    "    env = gym.make('Pendulum-v1', g=9.81)\n",
    "max_episodes = 1000\n",
    "max_steps = 200\n",
    "\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "# create training set\n",
    "training_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    observation, _ = env.reset()\n",
    "    for steps in range(max_steps+1):\n",
    "        action = env.action_space.sample() \n",
    "        next_observation, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        training_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the training set\")"
   ],
   "id": "f30d49f053f6de6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Secondly, we create the test set that we will use to evaluate the models.",
   "id": "2e77e79ba07b6ed3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:23:45.394304Z",
     "start_time": "2024-06-19T12:23:44.369057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create test set\n",
    "max_episodes_test = 100\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "testing_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "for episode in range(max_episodes_test):\n",
    "    observation, _ = env.reset()\n",
    "    for steps in range(max_steps + 1):\n",
    "        action = env.action_space.sample()  \n",
    "        next_observation, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        testing_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the test set\")"
   ],
   "id": "5c45b1ee713bfd84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the test set\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After creating train and test set, we are now ready to train the three models. We utilize the same learning rate, batch size, and number of traning epochs.\n",
   "id": "88bc1c0d153e505e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:23:45.623667Z",
     "start_time": "2024-06-19T12:23:45.395490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# learning the reward function of the pendulum\n",
    "from utils.models import FCNN, SparseFCNN, L0SINDy_reward\n",
    "from utils.trainer import train_eval_reward_model\n",
    "import torch\n",
    "\n",
    "# number of hidden units used by the fcnn_model and the sparsefcnn_model\n",
    "h_dim = 128\n",
    "\n",
    "# shared hyperparameter of the experiment\n",
    "lr = 3e-4\n",
    "batch_size = 256\n",
    "num_epochs = 500"
   ],
   "id": "e6093ecf746ff4b5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train and evaluate the fcnn_model.",
   "id": "5d92a884252b8594"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fcnn_model = FCNN(input_dim=obs_dim+act_dim, output_dim=1, h_dim=h_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fcnn_model = fcnn_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': fcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_fcnn = train_eval_reward_model(fcnn_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs)\n",
    "print(\"Best testing error FCNN is {} and it was found at epoch {}\".format(metrics_fcnn[2], metrics_fcnn[3]))"
   ],
   "id": "f406d37cdd49c6ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train and evaluate the sparsefcnn_model.",
   "id": "3fb8680d19f9c182"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reg_coefficient = 0.0005\n",
    "sparsefcnn_model = SparseFCNN(input_dim=obs_dim+act_dim, output_dim=1, h_dim=h_dim, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sparsefcnn_model = sparsefcnn_model.cuda()\n",
    "\n",
    "optimizer_sparsefcnn = torch.optim.Adam([\n",
    "    {'params': sparsefcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_sparsefcnn = train_eval_reward_model(sparsefcnn_model, optimizer_sparsefcnn, training_buffer, testing_buffer,\n",
    "                                               batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error sparse FCNN is {} and it was found at epoch {}\".format(metrics_sparsefcnn[2], metrics_sparsefcnn[3]))\n"
   ],
   "id": "90c9ca5b819b0c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train and evaluate the l0sindy_model.",
   "id": "f0b75e1648d9470d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# degree of the polynomial features\n",
    "degree = 3\n",
    "\n",
    "reg_coefficient = 0.0005\n",
    "l0sindy_model = L0SINDy_reward(input_dim=obs_dim+act_dim, output_dim=1, degree=degree, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    l0sindy_model = l0sindy_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': l0sindy_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_l0sindy = train_eval_reward_model(l0sindy_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error L0 SINDy is {} and it was found at epoch {}\".format(metrics_l0sindy[2], metrics_l0sindy[3]))\n",
    "\n",
    "l0sindy_model.print_equations()"
   ],
   "id": "d8761a32de0032cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eventually, we plot the mean-squared error between the predictions and the ground-truth over the training and test set.",
   "id": "70753772aa0dc06f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# creating the plots\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Training and Evaluation Metrics')\n",
    "\n",
    "data_train = {'FCNN': metrics_fcnn[0], 'SparseFCNN': metrics_sparsefcnn[0], 'L0SINDy': metrics_l0sindy[0]}\n",
    "methods_train = list(data_train.keys())\n",
    "values_train = list(data_train.values())\n",
    "\n",
    "# creating the bar plot\n",
    "ax1.bar(methods_train, values_train, color='maroon', width=0.4)\n",
    "\n",
    "data_eval = {'FCNN': metrics_fcnn[2], 'SparseFCNN': metrics_sparsefcnn[2], 'L0SINDy': metrics_l0sindy[2]}\n",
    "methods_eval = list(data_eval.keys())\n",
    "values_eval = list(data_eval.values())\n",
    "\n",
    "ax2.bar(methods_eval, values_eval, color='blue', width=0.4)\n",
    "\n",
    "save_dir = \"figures\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "fig.savefig('figures/LearningReward.png', dpi=300)"
   ],
   "id": "3f52e2a18f31e291",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
