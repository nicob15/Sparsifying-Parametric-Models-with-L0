{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:49:00.885978Z",
     "start_time": "2024-05-22T15:49:00.243375Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "from replay_buffer import ReplayBuffer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:49:12.690969Z",
     "start_time": "2024-05-22T15:49:02.589373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "render = False\n",
    "if render:\n",
    "    env = gym.make('Pendulum-v1', g=9.81, render_mode=\"human\")\n",
    "else:\n",
    "    env = gym.make('Pendulum-v1', g=9.81)\n",
    "max_episodes = 1000\n",
    "max_steps = 200\n",
    "\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "# create training set\n",
    "seed = 1\n",
    "training_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    observation, info = env.reset(seed=seed)\n",
    "    for steps in range(max_steps+1):\n",
    "        action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        training_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the training set\")"
   ],
   "id": "f30d49f053f6de6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolo/Documents/Sparsifying-Parametric-Models-with-L0/venv/lib/python3.10/site-packages/gymnasium/envs/classic_control/pendulum.py:173: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the training set\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:49:15.874716Z",
     "start_time": "2024-05-22T15:49:14.794624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create test set\n",
    "max_episodes_test = 100\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "seed = 7\n",
    "testing_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "for episode in range(max_episodes_test):\n",
    "    observation, info = env.reset(seed=seed)\n",
    "    for steps in range(max_steps + 1):\n",
    "        action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        testing_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the test set\")"
   ],
   "id": "5c45b1ee713bfd84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the test set\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:49:18.950846Z",
     "start_time": "2024-05-22T15:49:18.705231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# learning the reward function of the pendulum\n",
    "from models import FCNN, SparseFCNN, L0SINDy_reward\n",
    "from trainer import train_eval_reward_model\n",
    "import torch\n",
    "\n",
    "h_dim = 64\n",
    "lr = 3e-4\n",
    "batch_size = 256\n",
    "num_epochs = 50"
   ],
   "id": "e6093ecf746ff4b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:39:25.521224Z",
     "start_time": "2024-05-22T15:38:52.609756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fcnn_model = FCNN(input_dim=obs_dim+act_dim, output_dim=1, h_dim=h_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fcnn_model = fcnn_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': fcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_fcnn = train_eval_reward_model(fcnn_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs)\n",
    "print(\"Best testing error FCNN is {} and it was found at epoch {}\".format(metrics_fcnn[2], metrics_fcnn[3]))"
   ],
   "id": "f406d37cdd49c6ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average train loss: 5.0853429799\n",
      "====> Epoch: 0 Average eval loss: 0.8065864444\n",
      "====> Epoch: 1 Average train loss: 0.4510329755\n",
      "====> Epoch: 1 Average eval loss: 0.2876272798\n",
      "====> Epoch: 2 Average train loss: 0.1860080506\n",
      "====> Epoch: 2 Average eval loss: 0.1615861952\n",
      "====> Epoch: 3 Average train loss: 0.1095907881\n",
      "====> Epoch: 3 Average eval loss: 0.1100310534\n",
      "====> Epoch: 4 Average train loss: 0.0722869541\n",
      "====> Epoch: 4 Average eval loss: 0.0722475722\n",
      "====> Epoch: 5 Average train loss: 0.0474292982\n",
      "====> Epoch: 5 Average eval loss: 0.0481063426\n",
      "====> Epoch: 6 Average train loss: 0.0307188731\n",
      "====> Epoch: 6 Average eval loss: 0.0303153489\n",
      "====> Epoch: 7 Average train loss: 0.0208845843\n",
      "====> Epoch: 7 Average eval loss: 0.0208203830\n",
      "====> Epoch: 8 Average train loss: 0.0145904721\n",
      "====> Epoch: 8 Average eval loss: 0.0154579673\n",
      "====> Epoch: 9 Average train loss: 0.0109056870\n",
      "====> Epoch: 9 Average eval loss: 0.0110428771\n",
      "====> Epoch: 10 Average train loss: 0.0082877376\n",
      "====> Epoch: 10 Average eval loss: 0.0099285720\n",
      "====> Epoch: 11 Average train loss: 0.0063489666\n",
      "====> Epoch: 11 Average eval loss: 0.0064706793\n",
      "====> Epoch: 12 Average train loss: 0.0048366133\n",
      "====> Epoch: 12 Average eval loss: 0.0051388917\n",
      "====> Epoch: 13 Average train loss: 0.0039536147\n",
      "====> Epoch: 13 Average eval loss: 0.0041030198\n",
      "====> Epoch: 14 Average train loss: 0.0032331383\n",
      "====> Epoch: 14 Average eval loss: 0.0037608549\n",
      "====> Epoch: 15 Average train loss: 0.0029297905\n",
      "====> Epoch: 15 Average eval loss: 0.0031258720\n",
      "====> Epoch: 16 Average train loss: 0.0025304708\n",
      "====> Epoch: 16 Average eval loss: 0.0030566424\n",
      "====> Epoch: 17 Average train loss: 0.0022201807\n",
      "====> Epoch: 17 Average eval loss: 0.0024073590\n",
      "====> Epoch: 18 Average train loss: 0.0020066382\n",
      "====> Epoch: 18 Average eval loss: 0.0022437170\n",
      "====> Epoch: 19 Average train loss: 0.0018043887\n",
      "====> Epoch: 19 Average eval loss: 0.0020084486\n",
      "====> Epoch: 20 Average train loss: 0.0016805086\n",
      "====> Epoch: 20 Average eval loss: 0.0022519848\n",
      "====> Epoch: 21 Average train loss: 0.0015208011\n",
      "====> Epoch: 21 Average eval loss: 0.0018072278\n",
      "====> Epoch: 22 Average train loss: 0.0014445401\n",
      "====> Epoch: 22 Average eval loss: 0.0020805642\n",
      "====> Epoch: 23 Average train loss: 0.0013442726\n",
      "====> Epoch: 23 Average eval loss: 0.0018554081\n",
      "====> Epoch: 24 Average train loss: 0.0012643252\n",
      "====> Epoch: 24 Average eval loss: 0.0016324888\n",
      "====> Epoch: 25 Average train loss: 0.0012877487\n",
      "====> Epoch: 25 Average eval loss: 0.0014693994\n",
      "====> Epoch: 26 Average train loss: 0.0011239090\n",
      "====> Epoch: 26 Average eval loss: 0.0012596096\n",
      "====> Epoch: 27 Average train loss: 0.0010776310\n",
      "====> Epoch: 27 Average eval loss: 0.0013544584\n",
      "====> Epoch: 28 Average train loss: 0.0010347247\n",
      "====> Epoch: 28 Average eval loss: 0.0012083667\n",
      "====> Epoch: 29 Average train loss: 0.0010029451\n",
      "====> Epoch: 29 Average eval loss: 0.0013298242\n",
      "====> Epoch: 30 Average train loss: 0.0010018550\n",
      "====> Epoch: 30 Average eval loss: 0.0011161083\n",
      "====> Epoch: 31 Average train loss: 0.0009239291\n",
      "====> Epoch: 31 Average eval loss: 0.0010149989\n",
      "====> Epoch: 32 Average train loss: 0.0008884729\n",
      "====> Epoch: 32 Average eval loss: 0.0010622625\n",
      "====> Epoch: 33 Average train loss: 0.0008492077\n",
      "====> Epoch: 33 Average eval loss: 0.0015459993\n",
      "====> Epoch: 34 Average train loss: 0.0008762768\n",
      "====> Epoch: 34 Average eval loss: 0.0009575214\n",
      "====> Epoch: 35 Average train loss: 0.0008315567\n",
      "====> Epoch: 35 Average eval loss: 0.0009262918\n",
      "====> Epoch: 36 Average train loss: 0.0007588713\n",
      "====> Epoch: 36 Average eval loss: 0.0008878284\n",
      "====> Epoch: 37 Average train loss: 0.0007659950\n",
      "====> Epoch: 37 Average eval loss: 0.0009112762\n",
      "====> Epoch: 38 Average train loss: 0.0007917923\n",
      "====> Epoch: 38 Average eval loss: 0.0012342962\n",
      "====> Epoch: 39 Average train loss: 0.0007537788\n",
      "====> Epoch: 39 Average eval loss: 0.0009366270\n",
      "====> Epoch: 40 Average train loss: 0.0007147482\n",
      "====> Epoch: 40 Average eval loss: 0.0008692421\n",
      "====> Epoch: 41 Average train loss: 0.0007235590\n",
      "====> Epoch: 41 Average eval loss: 0.0008743500\n",
      "====> Epoch: 42 Average train loss: 0.0007028130\n",
      "====> Epoch: 42 Average eval loss: 0.0007637737\n",
      "====> Epoch: 43 Average train loss: 0.0006721018\n",
      "====> Epoch: 43 Average eval loss: 0.0008670731\n",
      "====> Epoch: 44 Average train loss: 0.0006341796\n",
      "====> Epoch: 44 Average eval loss: 0.0007335948\n",
      "====> Epoch: 45 Average train loss: 0.0006524306\n",
      "====> Epoch: 45 Average eval loss: 0.0007314028\n",
      "====> Epoch: 46 Average train loss: 0.0006389065\n",
      "====> Epoch: 46 Average eval loss: 0.0007906497\n",
      "====> Epoch: 47 Average train loss: 0.0006177619\n",
      "====> Epoch: 47 Average eval loss: 0.0007251861\n",
      "====> Epoch: 48 Average train loss: 0.0005992725\n",
      "====> Epoch: 48 Average eval loss: 0.0006195571\n",
      "====> Epoch: 49 Average train loss: 0.0006126460\n",
      "====> Epoch: 49 Average eval loss: 0.0006649287\n",
      "Best testing error FCNN is 0.0006195571040734649 and it was found at epoch 48\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:41:02.801243Z",
     "start_time": "2024-05-22T15:39:31.085611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reg_coefficient = 0.00001\n",
    "sparsefcnn_model = SparseFCNN(input_dim=obs_dim+act_dim, output_dim=1, h_dim=h_dim, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sparsefcnn_model = sparsefcnn_model.cuda()\n",
    "\n",
    "optimizer_sparsefcnn = torch.optim.Adam([\n",
    "    {'params': sparsefcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_sparsefcnn = train_eval_reward_model(sparsefcnn_model, optimizer_sparsefcnn, training_buffer, testing_buffer,\n",
    "                                               batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error sparse FCNN is {} and it was found at epoch {}\".format(metrics_sparsefcnn[2], metrics_sparsefcnn[3]))\n"
   ],
   "id": "90c9ca5b819b0c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolo/Documents/Sparsifying-Parametric-Models-with-L0/l0_layer.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.weights, mode='fan_out')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0Dense(4 -> 64, droprate_init=0.5, lamba=1e-05, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False)\n",
      "L0Dense(64 -> 64, droprate_init=0.5, lamba=1e-05, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False)\n",
      "L0Dense(64 -> 1, droprate_init=0.5, lamba=1e-05, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False)\n",
      "====> Epoch: 0 Average train loss: 19.8749318854\n",
      "====> Epoch: 0 Average L0 reg loss: 0.0368784434\n",
      "====> Epoch: 0 Average eval loss: 5.6155309677\n",
      "====> Epoch: 1 Average train loss: 10.0457300331\n",
      "====> Epoch: 1 Average L0 reg loss: 0.0370998036\n",
      "====> Epoch: 1 Average eval loss: 2.2697939873\n",
      "====> Epoch: 2 Average train loss: 7.6165008103\n",
      "====> Epoch: 2 Average L0 reg loss: 0.0372092764\n",
      "====> Epoch: 2 Average eval loss: 1.7601346970\n",
      "====> Epoch: 3 Average train loss: 6.5303920369\n",
      "====> Epoch: 3 Average L0 reg loss: 0.0372833702\n",
      "====> Epoch: 3 Average eval loss: 1.2636929750\n",
      "====> Epoch: 4 Average train loss: 5.8402730426\n",
      "====> Epoch: 4 Average L0 reg loss: 0.0373513191\n",
      "====> Epoch: 4 Average eval loss: 1.1614860296\n",
      "====> Epoch: 5 Average train loss: 5.3720257590\n",
      "====> Epoch: 5 Average L0 reg loss: 0.0374132787\n",
      "====> Epoch: 5 Average eval loss: 1.1698814631\n",
      "====> Epoch: 6 Average train loss: 5.1749612879\n",
      "====> Epoch: 6 Average L0 reg loss: 0.0374730582\n",
      "====> Epoch: 6 Average eval loss: 1.1209150553\n",
      "====> Epoch: 7 Average train loss: 5.1161738037\n",
      "====> Epoch: 7 Average L0 reg loss: 0.0375410430\n",
      "====> Epoch: 7 Average eval loss: 1.2013766766\n",
      "====> Epoch: 8 Average train loss: 4.5245679349\n",
      "====> Epoch: 8 Average L0 reg loss: 0.0375949704\n",
      "====> Epoch: 8 Average eval loss: 1.1249101162\n",
      "====> Epoch: 9 Average train loss: 4.4105464580\n",
      "====> Epoch: 9 Average L0 reg loss: 0.0376529465\n",
      "====> Epoch: 9 Average eval loss: 1.4370138645\n",
      "====> Epoch: 10 Average train loss: 3.9383953867\n",
      "====> Epoch: 10 Average L0 reg loss: 0.0377144151\n",
      "====> Epoch: 10 Average eval loss: 1.2448139191\n",
      "====> Epoch: 11 Average train loss: 3.9533436698\n",
      "====> Epoch: 11 Average L0 reg loss: 0.0377781759\n",
      "====> Epoch: 11 Average eval loss: 1.6576057673\n",
      "====> Epoch: 12 Average train loss: 3.6315226221\n",
      "====> Epoch: 12 Average L0 reg loss: 0.0378342472\n",
      "====> Epoch: 12 Average eval loss: 1.4741603136\n",
      "====> Epoch: 13 Average train loss: 3.5050608624\n",
      "====> Epoch: 13 Average L0 reg loss: 0.0378906058\n",
      "====> Epoch: 13 Average eval loss: 1.5041357279\n",
      "====> Epoch: 14 Average train loss: 3.5163504718\n",
      "====> Epoch: 14 Average L0 reg loss: 0.0379538786\n",
      "====> Epoch: 14 Average eval loss: 2.0119044781\n",
      "====> Epoch: 15 Average train loss: 3.2064808956\n",
      "====> Epoch: 15 Average L0 reg loss: 0.0380111967\n",
      "====> Epoch: 15 Average eval loss: 1.6199930906\n",
      "====> Epoch: 16 Average train loss: 2.9936970954\n",
      "====> Epoch: 16 Average L0 reg loss: 0.0380643472\n",
      "====> Epoch: 16 Average eval loss: 1.5698766708\n",
      "====> Epoch: 17 Average train loss: 2.8351214632\n",
      "====> Epoch: 17 Average L0 reg loss: 0.0381217624\n",
      "====> Epoch: 17 Average eval loss: 2.4272577763\n",
      "====> Epoch: 18 Average train loss: 2.6062388751\n",
      "====> Epoch: 18 Average L0 reg loss: 0.0381854346\n",
      "====> Epoch: 18 Average eval loss: 1.8446253538\n",
      "====> Epoch: 19 Average train loss: 2.5702278207\n",
      "====> Epoch: 19 Average L0 reg loss: 0.0382416321\n",
      "====> Epoch: 19 Average eval loss: 1.9696234465\n",
      "====> Epoch: 20 Average train loss: 2.3738123527\n",
      "====> Epoch: 20 Average L0 reg loss: 0.0382934688\n",
      "====> Epoch: 20 Average eval loss: 1.6789777279\n",
      "====> Epoch: 21 Average train loss: 2.3832659541\n",
      "====> Epoch: 21 Average L0 reg loss: 0.0383529225\n",
      "====> Epoch: 21 Average eval loss: 2.2444188595\n",
      "====> Epoch: 22 Average train loss: 2.3933994103\n",
      "====> Epoch: 22 Average L0 reg loss: 0.0384100613\n",
      "====> Epoch: 22 Average eval loss: 2.1438975334\n",
      "====> Epoch: 23 Average train loss: 2.4167752193\n",
      "====> Epoch: 23 Average L0 reg loss: 0.0384714752\n",
      "====> Epoch: 23 Average eval loss: 2.1424729824\n",
      "====> Epoch: 24 Average train loss: 2.1197016354\n",
      "====> Epoch: 24 Average L0 reg loss: 0.0385348945\n",
      "====> Epoch: 24 Average eval loss: 1.9953827858\n",
      "====> Epoch: 25 Average train loss: 2.0946457504\n",
      "====> Epoch: 25 Average L0 reg loss: 0.0385983571\n",
      "====> Epoch: 25 Average eval loss: 1.6534972191\n",
      "====> Epoch: 26 Average train loss: 1.9172463265\n",
      "====> Epoch: 26 Average L0 reg loss: 0.0386565138\n",
      "====> Epoch: 26 Average eval loss: 1.8991839886\n",
      "====> Epoch: 27 Average train loss: 2.0452506149\n",
      "====> Epoch: 27 Average L0 reg loss: 0.0387190166\n",
      "====> Epoch: 27 Average eval loss: 1.6985405684\n",
      "====> Epoch: 28 Average train loss: 1.8746209153\n",
      "====> Epoch: 28 Average L0 reg loss: 0.0387772718\n",
      "====> Epoch: 28 Average eval loss: 2.1160104275\n",
      "====> Epoch: 29 Average train loss: 1.8766078574\n",
      "====> Epoch: 29 Average L0 reg loss: 0.0388345760\n",
      "====> Epoch: 29 Average eval loss: 2.5472574234\n",
      "====> Epoch: 30 Average train loss: 1.7815744574\n",
      "====> Epoch: 30 Average L0 reg loss: 0.0388957397\n",
      "====> Epoch: 30 Average eval loss: 2.3629150391\n",
      "====> Epoch: 31 Average train loss: 1.8205816771\n",
      "====> Epoch: 31 Average L0 reg loss: 0.0389553755\n",
      "====> Epoch: 31 Average eval loss: 1.8679200411\n",
      "====> Epoch: 32 Average train loss: 1.7329051570\n",
      "====> Epoch: 32 Average L0 reg loss: 0.0390184749\n",
      "====> Epoch: 32 Average eval loss: 2.3578832150\n",
      "====> Epoch: 33 Average train loss: 1.4892098175\n",
      "====> Epoch: 33 Average L0 reg loss: 0.0390759993\n",
      "====> Epoch: 33 Average eval loss: 2.0358152390\n",
      "====> Epoch: 34 Average train loss: 1.6698325644\n",
      "====> Epoch: 34 Average L0 reg loss: 0.0391422112\n",
      "====> Epoch: 34 Average eval loss: 1.8323987722\n",
      "====> Epoch: 35 Average train loss: 1.4791205951\n",
      "====> Epoch: 35 Average L0 reg loss: 0.0392049815\n",
      "====> Epoch: 35 Average eval loss: 1.6382130384\n",
      "====> Epoch: 36 Average train loss: 1.5416449204\n",
      "====> Epoch: 36 Average L0 reg loss: 0.0392669114\n",
      "====> Epoch: 36 Average eval loss: 2.1473679543\n",
      "====> Epoch: 37 Average train loss: 1.4462536098\n",
      "====> Epoch: 37 Average L0 reg loss: 0.0393291938\n",
      "====> Epoch: 37 Average eval loss: 2.2542099953\n",
      "====> Epoch: 38 Average train loss: 1.4279947186\n",
      "====> Epoch: 38 Average L0 reg loss: 0.0393904611\n",
      "====> Epoch: 38 Average eval loss: 2.0751521587\n",
      "====> Epoch: 39 Average train loss: 1.3726379977\n",
      "====> Epoch: 39 Average L0 reg loss: 0.0394506591\n",
      "====> Epoch: 39 Average eval loss: 1.6286664009\n",
      "====> Epoch: 40 Average train loss: 1.3585588175\n",
      "====> Epoch: 40 Average L0 reg loss: 0.0395125008\n",
      "====> Epoch: 40 Average eval loss: 2.0760490894\n",
      "====> Epoch: 41 Average train loss: 1.2390429583\n",
      "====> Epoch: 41 Average L0 reg loss: 0.0395729422\n",
      "====> Epoch: 41 Average eval loss: 1.7441250086\n",
      "====> Epoch: 42 Average train loss: 1.1995791958\n",
      "====> Epoch: 42 Average L0 reg loss: 0.0396297971\n",
      "====> Epoch: 42 Average eval loss: 2.1831142902\n",
      "====> Epoch: 43 Average train loss: 1.1981083097\n",
      "====> Epoch: 43 Average L0 reg loss: 0.0396842246\n",
      "====> Epoch: 43 Average eval loss: 2.1234776974\n",
      "====> Epoch: 44 Average train loss: 1.2301888248\n",
      "====> Epoch: 44 Average L0 reg loss: 0.0397428855\n",
      "====> Epoch: 44 Average eval loss: 2.0044980049\n",
      "====> Epoch: 45 Average train loss: 1.2253860952\n",
      "====> Epoch: 45 Average L0 reg loss: 0.0398041670\n",
      "====> Epoch: 45 Average eval loss: 1.8266180754\n",
      "====> Epoch: 46 Average train loss: 1.2308769944\n",
      "====> Epoch: 46 Average L0 reg loss: 0.0398700861\n",
      "====> Epoch: 46 Average eval loss: 2.0717787743\n",
      "====> Epoch: 47 Average train loss: 1.1202824610\n",
      "====> Epoch: 47 Average L0 reg loss: 0.0399321362\n",
      "====> Epoch: 47 Average eval loss: 1.5920183659\n",
      "====> Epoch: 48 Average train loss: 1.1196503096\n",
      "====> Epoch: 48 Average L0 reg loss: 0.0399913270\n",
      "====> Epoch: 48 Average eval loss: 1.9272921085\n",
      "====> Epoch: 49 Average train loss: 1.0696592266\n",
      "====> Epoch: 49 Average L0 reg loss: 0.0400482436\n",
      "====> Epoch: 49 Average eval loss: 2.3013627529\n",
      "Best testing error sparse FCNN is 1.1209150552749634 and it was found at epoch 6\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:52:37.251241Z",
     "start_time": "2024-05-22T15:51:48.241318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "degree = 3\n",
    "reg_coefficient = 0.01\n",
    "l0sindy_model = L0SINDy_reward(input_dim=obs_dim+act_dim, output_dim=1, degree=degree, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    l0sindy_model = l0sindy_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': l0sindy_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_l0sindy = train_eval_reward_model(l0sindy_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error L0 SINDy is {} and it was found at epoch {}\".format(metrics_l0sindy[2], metrics_l0sindy[3]))\n"
   ],
   "id": "d8761a32de0032cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy polynomial of order  3\n",
      "with 35 coefficients\n",
      "['1' 'x0' 'x1' 'x2' 'x3' 'x0^2' 'x0 x1' 'x0 x2' 'x0 x3' 'x1^2' 'x1 x2'\n",
      " 'x1 x3' 'x2^2' 'x2 x3' 'x3^2' 'x0^3' 'x0^2 x1' 'x0^2 x2' 'x0^2 x3'\n",
      " 'x0 x1^2' 'x0 x1 x2' 'x0 x1 x3' 'x0 x2^2' 'x0 x2 x3' 'x0 x3^2' 'x1^3'\n",
      " 'x1^2 x2' 'x1^2 x3' 'x1 x2^2' 'x1 x2 x3' 'x1 x3^2' 'x2^3' 'x2^2 x3'\n",
      " 'x2 x3^2' 'x3^3']\n",
      "L0Dense(35 -> 1, droprate_init=0.5, lamba=0.01, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False, bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolo/Documents/Sparsifying-Parametric-Models-with-L0/l0_layer.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.weights, mode='fan_out')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average train loss: 860.1311251191\n",
      "====> Epoch: 0 Average L0 reg loss: 0.2908181244\n",
      "====> Epoch: 0 Average eval loss: 191.3743743896\n",
      "====> Epoch: 1 Average train loss: 220.3858759361\n",
      "====> Epoch: 1 Average L0 reg loss: 0.2911279030\n",
      "====> Epoch: 1 Average eval loss: 28.2232437134\n",
      "====> Epoch: 2 Average train loss: 42.9168661465\n",
      "====> Epoch: 2 Average L0 reg loss: 0.2911557696\n",
      "====> Epoch: 2 Average eval loss: 4.3544363976\n",
      "====> Epoch: 3 Average train loss: 14.5236438739\n",
      "====> Epoch: 3 Average L0 reg loss: 0.2908907707\n",
      "====> Epoch: 3 Average eval loss: 4.2804379463\n",
      "====> Epoch: 4 Average train loss: 10.4002836793\n",
      "====> Epoch: 4 Average L0 reg loss: 0.2905083405\n",
      "====> Epoch: 4 Average eval loss: 3.8734283447\n",
      "====> Epoch: 5 Average train loss: 9.1733456146\n",
      "====> Epoch: 5 Average L0 reg loss: 0.2900795895\n",
      "====> Epoch: 5 Average eval loss: 3.0318460464\n",
      "====> Epoch: 6 Average train loss: 8.0199446121\n",
      "====> Epoch: 6 Average L0 reg loss: 0.2894383367\n",
      "====> Epoch: 6 Average eval loss: 2.5213730335\n",
      "====> Epoch: 7 Average train loss: 6.6857077456\n",
      "====> Epoch: 7 Average L0 reg loss: 0.2884596897\n",
      "====> Epoch: 7 Average eval loss: 1.8124190569\n",
      "====> Epoch: 8 Average train loss: 5.6795132463\n",
      "====> Epoch: 8 Average L0 reg loss: 0.2870514562\n",
      "====> Epoch: 8 Average eval loss: 1.6561925411\n",
      "====> Epoch: 9 Average train loss: 5.3100889222\n",
      "====> Epoch: 9 Average L0 reg loss: 0.2852459191\n",
      "====> Epoch: 9 Average eval loss: 1.3295689821\n",
      "====> Epoch: 10 Average train loss: 4.8032305686\n",
      "====> Epoch: 10 Average L0 reg loss: 0.2829727126\n",
      "====> Epoch: 10 Average eval loss: 1.0986212492\n",
      "====> Epoch: 11 Average train loss: 4.1767610300\n",
      "====> Epoch: 11 Average L0 reg loss: 0.2801173101\n",
      "====> Epoch: 11 Average eval loss: 0.9140255451\n",
      "====> Epoch: 12 Average train loss: 3.7865262493\n",
      "====> Epoch: 12 Average L0 reg loss: 0.2766723497\n",
      "====> Epoch: 12 Average eval loss: 0.8469061255\n",
      "====> Epoch: 13 Average train loss: 3.6077065774\n",
      "====> Epoch: 13 Average L0 reg loss: 0.2725350692\n",
      "====> Epoch: 13 Average eval loss: 0.6738052368\n",
      "====> Epoch: 14 Average train loss: 3.1353967679\n",
      "====> Epoch: 14 Average L0 reg loss: 0.2676933768\n",
      "====> Epoch: 14 Average eval loss: 0.6176620126\n",
      "====> Epoch: 15 Average train loss: 3.1604153433\n",
      "====> Epoch: 15 Average L0 reg loss: 0.2621379474\n",
      "====> Epoch: 15 Average eval loss: 0.5808318853\n",
      "====> Epoch: 16 Average train loss: 2.9451540445\n",
      "====> Epoch: 16 Average L0 reg loss: 0.2558826326\n",
      "====> Epoch: 16 Average eval loss: 0.5742275119\n",
      "====> Epoch: 17 Average train loss: 2.7083100245\n",
      "====> Epoch: 17 Average L0 reg loss: 0.2489707773\n",
      "====> Epoch: 17 Average eval loss: 0.5602090955\n",
      "====> Epoch: 18 Average train loss: 2.3697866958\n",
      "====> Epoch: 18 Average L0 reg loss: 0.2415679454\n",
      "====> Epoch: 18 Average eval loss: 0.5028384328\n",
      "====> Epoch: 19 Average train loss: 2.1469458722\n",
      "====> Epoch: 19 Average L0 reg loss: 0.2338587957\n",
      "====> Epoch: 19 Average eval loss: 0.4959280193\n",
      "====> Epoch: 20 Average train loss: 2.0662858622\n",
      "====> Epoch: 20 Average L0 reg loss: 0.2260568535\n",
      "====> Epoch: 20 Average eval loss: 0.4309562445\n",
      "====> Epoch: 21 Average train loss: 1.8310062190\n",
      "====> Epoch: 21 Average L0 reg loss: 0.2183646154\n",
      "====> Epoch: 21 Average eval loss: 0.4729129672\n",
      "====> Epoch: 22 Average train loss: 2.0077817158\n",
      "====> Epoch: 22 Average L0 reg loss: 0.2108684994\n",
      "====> Epoch: 22 Average eval loss: 0.4656560421\n",
      "====> Epoch: 23 Average train loss: 1.7272639841\n",
      "====> Epoch: 23 Average L0 reg loss: 0.2037217963\n",
      "====> Epoch: 23 Average eval loss: 0.4284450114\n",
      "====> Epoch: 24 Average train loss: 1.6163701167\n",
      "====> Epoch: 24 Average L0 reg loss: 0.1969284609\n",
      "====> Epoch: 24 Average eval loss: 0.5250095725\n",
      "====> Epoch: 25 Average train loss: 1.4734715588\n",
      "====> Epoch: 25 Average L0 reg loss: 0.1904782019\n",
      "====> Epoch: 25 Average eval loss: 0.4835886657\n",
      "====> Epoch: 26 Average train loss: 1.4201088785\n",
      "====> Epoch: 26 Average L0 reg loss: 0.1844800594\n",
      "====> Epoch: 26 Average eval loss: 0.4413147271\n",
      "====> Epoch: 27 Average train loss: 1.2384954576\n",
      "====> Epoch: 27 Average L0 reg loss: 0.1788574222\n",
      "====> Epoch: 27 Average eval loss: 0.4652553201\n",
      "====> Epoch: 28 Average train loss: 1.2740245955\n",
      "====> Epoch: 28 Average L0 reg loss: 0.1735510479\n",
      "====> Epoch: 28 Average eval loss: 0.4681427479\n",
      "====> Epoch: 29 Average train loss: 1.2497462631\n",
      "====> Epoch: 29 Average L0 reg loss: 0.1687111084\n",
      "====> Epoch: 29 Average eval loss: 0.4950564206\n",
      "====> Epoch: 30 Average train loss: 1.1097338720\n",
      "====> Epoch: 30 Average L0 reg loss: 0.1641685201\n",
      "====> Epoch: 30 Average eval loss: 0.4077433944\n",
      "====> Epoch: 31 Average train loss: 1.0775883054\n",
      "====> Epoch: 31 Average L0 reg loss: 0.1599450349\n",
      "====> Epoch: 31 Average eval loss: 0.3501192331\n",
      "====> Epoch: 32 Average train loss: 0.8878925837\n",
      "====> Epoch: 32 Average L0 reg loss: 0.1559586993\n",
      "====> Epoch: 32 Average eval loss: 0.3118979037\n",
      "====> Epoch: 33 Average train loss: 1.0008183744\n",
      "====> Epoch: 33 Average L0 reg loss: 0.1520534445\n",
      "====> Epoch: 33 Average eval loss: 0.3163371384\n",
      "====> Epoch: 34 Average train loss: 0.9627084350\n",
      "====> Epoch: 34 Average L0 reg loss: 0.1482728778\n",
      "====> Epoch: 34 Average eval loss: 0.2964716852\n",
      "====> Epoch: 35 Average train loss: 1.0432416955\n",
      "====> Epoch: 35 Average L0 reg loss: 0.1446793866\n",
      "====> Epoch: 35 Average eval loss: 0.3209217191\n",
      "====> Epoch: 36 Average train loss: 0.8399822066\n",
      "====> Epoch: 36 Average L0 reg loss: 0.1413993758\n",
      "====> Epoch: 36 Average eval loss: 0.3433061242\n",
      "====> Epoch: 37 Average train loss: 0.7288241375\n",
      "====> Epoch: 37 Average L0 reg loss: 0.1382086426\n",
      "====> Epoch: 37 Average eval loss: 0.2445264757\n",
      "====> Epoch: 38 Average train loss: 0.7330422979\n",
      "====> Epoch: 38 Average L0 reg loss: 0.1350064074\n",
      "====> Epoch: 38 Average eval loss: 0.2313402295\n",
      "====> Epoch: 39 Average train loss: 0.7631211243\n",
      "====> Epoch: 39 Average L0 reg loss: 0.1318332289\n",
      "====> Epoch: 39 Average eval loss: 0.2484590709\n",
      "====> Epoch: 40 Average train loss: 0.6679352877\n",
      "====> Epoch: 40 Average L0 reg loss: 0.1288484657\n",
      "====> Epoch: 40 Average eval loss: 0.2484685034\n",
      "====> Epoch: 41 Average train loss: 0.6961807869\n",
      "====> Epoch: 41 Average L0 reg loss: 0.1260059651\n",
      "====> Epoch: 41 Average eval loss: 0.2569911182\n",
      "====> Epoch: 42 Average train loss: 0.6358637973\n",
      "====> Epoch: 42 Average L0 reg loss: 0.1232767978\n",
      "====> Epoch: 42 Average eval loss: 0.2526398003\n",
      "====> Epoch: 43 Average train loss: 0.6019848375\n",
      "====> Epoch: 43 Average L0 reg loss: 0.1207642140\n",
      "====> Epoch: 43 Average eval loss: 0.1867737025\n",
      "====> Epoch: 44 Average train loss: 0.5498366873\n",
      "====> Epoch: 44 Average L0 reg loss: 0.1184575337\n",
      "====> Epoch: 44 Average eval loss: 0.1717070043\n",
      "====> Epoch: 45 Average train loss: 0.4836937127\n",
      "====> Epoch: 45 Average L0 reg loss: 0.1163013629\n",
      "====> Epoch: 45 Average eval loss: 0.1779419780\n",
      "====> Epoch: 46 Average train loss: 0.5546664912\n",
      "====> Epoch: 46 Average L0 reg loss: 0.1143915525\n",
      "====> Epoch: 46 Average eval loss: 0.1810371429\n",
      "====> Epoch: 47 Average train loss: 0.4328441467\n",
      "====> Epoch: 47 Average L0 reg loss: 0.1126823025\n",
      "====> Epoch: 47 Average eval loss: 0.1754314750\n",
      "====> Epoch: 48 Average train loss: 0.4630725576\n",
      "====> Epoch: 48 Average L0 reg loss: 0.1111658287\n",
      "====> Epoch: 48 Average eval loss: 0.1507905722\n",
      "====> Epoch: 49 Average train loss: 0.4001962422\n",
      "====> Epoch: 49 Average L0 reg loss: 0.1097746739\n",
      "====> Epoch: 49 Average eval loss: 0.1446280926\n",
      "Best testing error L0 SINDy is 0.14462809264659882 and it was found at epoch 49\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# creating the plots\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Training and Evaluation Metrics')\n",
    "\n",
    "data_train = {'FCNN (train)': metrics_fcnn[0], 'SparseFCNN (train)': metrics_sparsefcnn[0], 'L0SINDy (train)': metrics_l0sindy[0]}\n",
    "methods_train = list(data_train.keys())\n",
    "values_train = list(data_train.values())\n",
    "\n",
    "# creating the bar plot\n",
    "ax1.bar(methods_train, values_train, color='maroon', width=0.4)\n",
    "\n",
    "data_eval = {'FCNN (eval)': metrics_fcnn[1], 'SparseFCNN (eval)': metrics_sparsefcnn[1], 'L0SINDy (eval)': metrics_l0sindy[0]}\n",
    "methods_eval = list(data_eval.keys())\n",
    "values_eval = list(data_eval.values())\n",
    "\n",
    "ax2.bar(methods_eval, values_eval, color='blue', width=0.4)\n",
    "\n",
    "save_dir = \"figures\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "fig.savefig('figures/LearningReward.png', dpi=300)"
   ],
   "id": "3f52e2a18f31e291"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
