{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:42.858100Z",
     "start_time": "2024-05-22T15:56:42.298421Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "from replay_buffer import ReplayBuffer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds\n",
    "seed = 23524\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:54.933106Z",
     "start_time": "2024-05-22T15:56:45.155388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "render = False\n",
    "if render:\n",
    "    env = gym.make('Pendulum-v1', g=9.81, render_mode=\"human\")\n",
    "else:\n",
    "    env = gym.make('Pendulum-v1', g=9.81)\n",
    "max_episodes = 1000\n",
    "max_steps = 200\n",
    "\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "# create training set\n",
    "seed = 1\n",
    "training_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    observation, info = env.reset()\n",
    "    for steps in range(max_steps+1):\n",
    "        action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        training_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the training set\")"
   ],
   "id": "f30d49f053f6de6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolo/Documents/Sparsifying-Parametric-Models-with-L0/venv/lib/python3.10/site-packages/gymnasium/envs/classic_control/pendulum.py:173: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the training set\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:57.188312Z",
     "start_time": "2024-05-22T15:56:56.139432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create test set\n",
    "max_episodes_test = 100\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "seed = 7\n",
    "testing_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "for episode in range(max_episodes_test):\n",
    "    observation, info = env.reset()\n",
    "    for steps in range(max_steps + 1):\n",
    "        action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        testing_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the test set\")"
   ],
   "id": "5c45b1ee713bfd84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the test set\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:58:51.142599Z",
     "start_time": "2024-05-22T15:58:51.139651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# learning the reward function of the pendulum\n",
    "from models import FCNN, SparseFCNN, L0SINDy_reward\n",
    "from trainer import train_eval_reward_model\n",
    "import torch\n",
    "\n",
    "h_dim = 64\n",
    "lr = 3e-4\n",
    "batch_size = 256\n",
    "num_epochs = 250"
   ],
   "id": "e6093ecf746ff4b5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:59:56.980690Z",
     "start_time": "2024-05-22T15:58:53.142594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fcnn_model = FCNN(input_dim=obs_dim+act_dim, output_dim=1, h_dim=h_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fcnn_model = fcnn_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': fcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_fcnn = train_eval_reward_model(fcnn_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs)\n",
    "print(\"Best testing error FCNN is {} and it was found at epoch {}\".format(metrics_fcnn[2], metrics_fcnn[3]))"
   ],
   "id": "f406d37cdd49c6ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average train loss: 4.5532885354\n",
      "====> Epoch: 0 Average eval loss: 0.8333411813\n",
      "====> Epoch: 1 Average train loss: 0.4758645585\n",
      "====> Epoch: 1 Average eval loss: 0.2788564861\n",
      "====> Epoch: 2 Average train loss: 0.1765703295\n",
      "====> Epoch: 2 Average eval loss: 0.1315535605\n",
      "====> Epoch: 3 Average train loss: 0.0863454963\n",
      "====> Epoch: 3 Average eval loss: 0.0720449686\n",
      "====> Epoch: 4 Average train loss: 0.0488883006\n",
      "====> Epoch: 4 Average eval loss: 0.0438866690\n",
      "====> Epoch: 5 Average train loss: 0.0312165852\n",
      "====> Epoch: 5 Average eval loss: 0.0289557800\n",
      "====> Epoch: 6 Average train loss: 0.0218273979\n",
      "====> Epoch: 6 Average eval loss: 0.0212480724\n",
      "====> Epoch: 7 Average train loss: 0.0164285934\n",
      "====> Epoch: 7 Average eval loss: 0.0160472766\n",
      "====> Epoch: 8 Average train loss: 0.0124407734\n",
      "====> Epoch: 8 Average eval loss: 0.0127961803\n",
      "====> Epoch: 9 Average train loss: 0.0096399154\n",
      "====> Epoch: 9 Average eval loss: 0.0095420945\n",
      "====> Epoch: 10 Average train loss: 0.0073382032\n",
      "====> Epoch: 10 Average eval loss: 0.0069494559\n",
      "====> Epoch: 11 Average train loss: 0.0057390751\n",
      "====> Epoch: 11 Average eval loss: 0.0058796834\n",
      "====> Epoch: 12 Average train loss: 0.0044152310\n",
      "====> Epoch: 12 Average eval loss: 0.0042699147\n",
      "====> Epoch: 13 Average train loss: 0.0035947771\n",
      "====> Epoch: 13 Average eval loss: 0.0035664618\n",
      "====> Epoch: 14 Average train loss: 0.0029073929\n",
      "====> Epoch: 14 Average eval loss: 0.0030459121\n",
      "====> Epoch: 15 Average train loss: 0.0025115204\n",
      "====> Epoch: 15 Average eval loss: 0.0025616579\n",
      "====> Epoch: 16 Average train loss: 0.0022058738\n",
      "====> Epoch: 16 Average eval loss: 0.0027606483\n",
      "====> Epoch: 17 Average train loss: 0.0019999978\n",
      "====> Epoch: 17 Average eval loss: 0.0019167128\n",
      "====> Epoch: 18 Average train loss: 0.0018261999\n",
      "====> Epoch: 18 Average eval loss: 0.0017776653\n",
      "====> Epoch: 19 Average train loss: 0.0016067808\n",
      "====> Epoch: 19 Average eval loss: 0.0017596445\n",
      "====> Epoch: 20 Average train loss: 0.0015317484\n",
      "====> Epoch: 20 Average eval loss: 0.0015547404\n",
      "====> Epoch: 21 Average train loss: 0.0014243619\n",
      "====> Epoch: 21 Average eval loss: 0.0015211651\n",
      "====> Epoch: 22 Average train loss: 0.0013270075\n",
      "====> Epoch: 22 Average eval loss: 0.0016726588\n",
      "====> Epoch: 23 Average train loss: 0.0012385722\n",
      "====> Epoch: 23 Average eval loss: 0.0013967032\n",
      "====> Epoch: 24 Average train loss: 0.0011975183\n",
      "====> Epoch: 24 Average eval loss: 0.0013089299\n",
      "====> Epoch: 25 Average train loss: 0.0010968792\n",
      "====> Epoch: 25 Average eval loss: 0.0011683225\n",
      "====> Epoch: 26 Average train loss: 0.0010123864\n",
      "====> Epoch: 26 Average eval loss: 0.0011659777\n",
      "====> Epoch: 27 Average train loss: 0.0009997113\n",
      "====> Epoch: 27 Average eval loss: 0.0009438337\n",
      "====> Epoch: 28 Average train loss: 0.0009632778\n",
      "====> Epoch: 28 Average eval loss: 0.0019292781\n",
      "====> Epoch: 29 Average train loss: 0.0008736507\n",
      "====> Epoch: 29 Average eval loss: 0.0009164615\n",
      "====> Epoch: 30 Average train loss: 0.0008475996\n",
      "====> Epoch: 30 Average eval loss: 0.0008771133\n",
      "====> Epoch: 31 Average train loss: 0.0008523557\n",
      "====> Epoch: 31 Average eval loss: 0.0010721323\n",
      "====> Epoch: 32 Average train loss: 0.0007910170\n",
      "====> Epoch: 32 Average eval loss: 0.0007876714\n",
      "====> Epoch: 33 Average train loss: 0.0007928878\n",
      "====> Epoch: 33 Average eval loss: 0.0007667617\n",
      "====> Epoch: 34 Average train loss: 0.0007203504\n",
      "====> Epoch: 34 Average eval loss: 0.0008387518\n",
      "====> Epoch: 35 Average train loss: 0.0007167777\n",
      "====> Epoch: 35 Average eval loss: 0.0007139530\n",
      "====> Epoch: 36 Average train loss: 0.0006684843\n",
      "====> Epoch: 36 Average eval loss: 0.0007358355\n",
      "====> Epoch: 37 Average train loss: 0.0006752055\n",
      "====> Epoch: 37 Average eval loss: 0.0006796396\n",
      "====> Epoch: 38 Average train loss: 0.0006409025\n",
      "====> Epoch: 38 Average eval loss: 0.0007519423\n",
      "====> Epoch: 39 Average train loss: 0.0006378988\n",
      "====> Epoch: 39 Average eval loss: 0.0006282490\n",
      "====> Epoch: 40 Average train loss: 0.0006222188\n",
      "====> Epoch: 40 Average eval loss: 0.0007813578\n",
      "====> Epoch: 41 Average train loss: 0.0005883558\n",
      "====> Epoch: 41 Average eval loss: 0.0006268183\n",
      "====> Epoch: 42 Average train loss: 0.0005375515\n",
      "====> Epoch: 42 Average eval loss: 0.0013258553\n",
      "====> Epoch: 43 Average train loss: 0.0005780087\n",
      "====> Epoch: 43 Average eval loss: 0.0006790760\n",
      "====> Epoch: 44 Average train loss: 0.0005411663\n",
      "====> Epoch: 44 Average eval loss: 0.0007974828\n",
      "====> Epoch: 45 Average train loss: 0.0005383874\n",
      "====> Epoch: 45 Average eval loss: 0.0005111275\n",
      "====> Epoch: 46 Average train loss: 0.0005121233\n",
      "====> Epoch: 46 Average eval loss: 0.0004997677\n",
      "====> Epoch: 47 Average train loss: 0.0005211337\n",
      "====> Epoch: 47 Average eval loss: 0.0004673429\n",
      "====> Epoch: 48 Average train loss: 0.0005103653\n",
      "====> Epoch: 48 Average eval loss: 0.0004645950\n",
      "====> Epoch: 49 Average train loss: 0.0004788980\n",
      "====> Epoch: 49 Average eval loss: 0.0004945706\n",
      "====> Epoch: 50 Average train loss: 0.0004701579\n",
      "====> Epoch: 50 Average eval loss: 0.0004738398\n",
      "====> Epoch: 51 Average train loss: 0.0004622750\n",
      "====> Epoch: 51 Average eval loss: 0.0007090917\n",
      "====> Epoch: 52 Average train loss: 0.0004644881\n",
      "====> Epoch: 52 Average eval loss: 0.0006664963\n",
      "====> Epoch: 53 Average train loss: 0.0004781369\n",
      "====> Epoch: 53 Average eval loss: 0.0004396990\n",
      "====> Epoch: 54 Average train loss: 0.0004182463\n",
      "====> Epoch: 54 Average eval loss: 0.0004693941\n",
      "====> Epoch: 55 Average train loss: 0.0004528878\n",
      "====> Epoch: 55 Average eval loss: 0.0004558330\n",
      "====> Epoch: 56 Average train loss: 0.0003926033\n",
      "====> Epoch: 56 Average eval loss: 0.0004354900\n",
      "====> Epoch: 57 Average train loss: 0.0004018687\n",
      "====> Epoch: 57 Average eval loss: 0.0005723726\n",
      "====> Epoch: 58 Average train loss: 0.0004007217\n",
      "====> Epoch: 58 Average eval loss: 0.0006889908\n",
      "====> Epoch: 59 Average train loss: 0.0003856785\n",
      "====> Epoch: 59 Average eval loss: 0.0004750047\n",
      "====> Epoch: 60 Average train loss: 0.0004047280\n",
      "====> Epoch: 60 Average eval loss: 0.0003542363\n",
      "====> Epoch: 61 Average train loss: 0.0003803446\n",
      "====> Epoch: 61 Average eval loss: 0.0004142001\n",
      "====> Epoch: 62 Average train loss: 0.0003648195\n",
      "====> Epoch: 62 Average eval loss: 0.0003222236\n",
      "====> Epoch: 63 Average train loss: 0.0003576651\n",
      "====> Epoch: 63 Average eval loss: 0.0003593509\n",
      "====> Epoch: 64 Average train loss: 0.0003754008\n",
      "====> Epoch: 64 Average eval loss: 0.0003914271\n",
      "====> Epoch: 65 Average train loss: 0.0003523700\n",
      "====> Epoch: 65 Average eval loss: 0.0003199038\n",
      "====> Epoch: 66 Average train loss: 0.0003424334\n",
      "====> Epoch: 66 Average eval loss: 0.0003630109\n",
      "====> Epoch: 67 Average train loss: 0.0003352356\n",
      "====> Epoch: 67 Average eval loss: 0.0003125459\n",
      "====> Epoch: 68 Average train loss: 0.0003654217\n",
      "====> Epoch: 68 Average eval loss: 0.0003239328\n",
      "====> Epoch: 69 Average train loss: 0.0003273286\n",
      "====> Epoch: 69 Average eval loss: 0.0004878534\n",
      "====> Epoch: 70 Average train loss: 0.0003088987\n",
      "====> Epoch: 70 Average eval loss: 0.0003081344\n",
      "====> Epoch: 71 Average train loss: 0.0003342986\n",
      "====> Epoch: 71 Average eval loss: 0.0004540336\n",
      "====> Epoch: 72 Average train loss: 0.0003067330\n",
      "====> Epoch: 72 Average eval loss: 0.0002855678\n",
      "====> Epoch: 73 Average train loss: 0.0002998449\n",
      "====> Epoch: 73 Average eval loss: 0.0003943038\n",
      "====> Epoch: 74 Average train loss: 0.0003014793\n",
      "====> Epoch: 74 Average eval loss: 0.0005352355\n",
      "====> Epoch: 75 Average train loss: 0.0002896524\n",
      "====> Epoch: 75 Average eval loss: 0.0002700867\n",
      "====> Epoch: 76 Average train loss: 0.0002786290\n",
      "====> Epoch: 76 Average eval loss: 0.0003085174\n",
      "====> Epoch: 77 Average train loss: 0.0002916783\n",
      "====> Epoch: 77 Average eval loss: 0.0003192277\n",
      "====> Epoch: 78 Average train loss: 0.0002984144\n",
      "====> Epoch: 78 Average eval loss: 0.0002779356\n",
      "====> Epoch: 79 Average train loss: 0.0002858526\n",
      "====> Epoch: 79 Average eval loss: 0.0002657107\n",
      "====> Epoch: 80 Average train loss: 0.0002699826\n",
      "====> Epoch: 80 Average eval loss: 0.0003286182\n",
      "====> Epoch: 81 Average train loss: 0.0002887421\n",
      "====> Epoch: 81 Average eval loss: 0.0002319253\n",
      "====> Epoch: 82 Average train loss: 0.0002661263\n",
      "====> Epoch: 82 Average eval loss: 0.0002683882\n",
      "====> Epoch: 83 Average train loss: 0.0002726636\n",
      "====> Epoch: 83 Average eval loss: 0.0002417963\n",
      "====> Epoch: 84 Average train loss: 0.0002644262\n",
      "====> Epoch: 84 Average eval loss: 0.0002830568\n",
      "====> Epoch: 85 Average train loss: 0.0002625747\n",
      "====> Epoch: 85 Average eval loss: 0.0002203246\n",
      "====> Epoch: 86 Average train loss: 0.0002562470\n",
      "====> Epoch: 86 Average eval loss: 0.0002300440\n",
      "====> Epoch: 87 Average train loss: 0.0002508195\n",
      "====> Epoch: 87 Average eval loss: 0.0002508370\n",
      "====> Epoch: 88 Average train loss: 0.0002473690\n",
      "====> Epoch: 88 Average eval loss: 0.0002240705\n",
      "====> Epoch: 89 Average train loss: 0.0002262811\n",
      "====> Epoch: 89 Average eval loss: 0.0002695880\n",
      "====> Epoch: 90 Average train loss: 0.0002593623\n",
      "====> Epoch: 90 Average eval loss: 0.0002346109\n",
      "====> Epoch: 91 Average train loss: 0.0002385603\n",
      "====> Epoch: 91 Average eval loss: 0.0002661288\n",
      "====> Epoch: 92 Average train loss: 0.0002310007\n",
      "====> Epoch: 92 Average eval loss: 0.0002209045\n",
      "====> Epoch: 93 Average train loss: 0.0002303924\n",
      "====> Epoch: 93 Average eval loss: 0.0002214151\n",
      "====> Epoch: 94 Average train loss: 0.0002378788\n",
      "====> Epoch: 94 Average eval loss: 0.0003351581\n",
      "====> Epoch: 95 Average train loss: 0.0002180080\n",
      "====> Epoch: 95 Average eval loss: 0.0002251193\n",
      "====> Epoch: 96 Average train loss: 0.0002387981\n",
      "====> Epoch: 96 Average eval loss: 0.0002727048\n",
      "====> Epoch: 97 Average train loss: 0.0002257932\n",
      "====> Epoch: 97 Average eval loss: 0.0002499712\n",
      "====> Epoch: 98 Average train loss: 0.0002176474\n",
      "====> Epoch: 98 Average eval loss: 0.0002129895\n",
      "====> Epoch: 99 Average train loss: 0.0002199467\n",
      "====> Epoch: 99 Average eval loss: 0.0002556227\n",
      "Best testing error FCNN is 0.00021298947103787214 and it was found at epoch 98\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T16:05:56.567238Z",
     "start_time": "2024-05-22T16:03:32.223272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reg_coefficient = 0.0005\n",
    "sparsefcnn_model = SparseFCNN(input_dim=obs_dim+act_dim, output_dim=1, h_dim=h_dim, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sparsefcnn_model = sparsefcnn_model.cuda()\n",
    "\n",
    "optimizer_sparsefcnn = torch.optim.Adam([\n",
    "    {'params': sparsefcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_sparsefcnn = train_eval_reward_model(sparsefcnn_model, optimizer_sparsefcnn, training_buffer, testing_buffer,\n",
    "                                               batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error sparse FCNN is {} and it was found at epoch {}\".format(metrics_sparsefcnn[2], metrics_sparsefcnn[3]))\n"
   ],
   "id": "90c9ca5b819b0c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0Dense(4 -> 64, droprate_init=0.5, lamba=0.0, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False)\n",
      "L0Dense(64 -> 64, droprate_init=0.5, lamba=0.0, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False)\n",
      "L0Dense(64 -> 1, droprate_init=0.5, lamba=0.0, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False)\n",
      "====> Epoch: 0 Average train loss: 20.4251257673\n",
      "====> Epoch: 0 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 0 Average eval loss: 5.3435335159\n",
      "====> Epoch: 1 Average train loss: 9.4822535194\n",
      "====> Epoch: 1 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 1 Average eval loss: 2.5392119884\n",
      "====> Epoch: 2 Average train loss: 7.5680965167\n",
      "====> Epoch: 2 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 2 Average eval loss: 1.7159489393\n",
      "====> Epoch: 3 Average train loss: 6.7233237378\n",
      "====> Epoch: 3 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 3 Average eval loss: 1.2898246050\n",
      "====> Epoch: 4 Average train loss: 5.6556191096\n",
      "====> Epoch: 4 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 4 Average eval loss: 1.0597745180\n",
      "====> Epoch: 5 Average train loss: 5.4667721056\n",
      "====> Epoch: 5 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 5 Average eval loss: 0.9571413994\n",
      "====> Epoch: 6 Average train loss: 5.2584768981\n",
      "====> Epoch: 6 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 6 Average eval loss: 0.9125061035\n",
      "====> Epoch: 7 Average train loss: 4.7083785793\n",
      "====> Epoch: 7 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 7 Average eval loss: 0.8349159956\n",
      "====> Epoch: 8 Average train loss: 4.5760417127\n",
      "====> Epoch: 8 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 8 Average eval loss: 0.8447837830\n",
      "====> Epoch: 9 Average train loss: 3.8326280040\n",
      "====> Epoch: 9 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 9 Average eval loss: 0.8269984126\n",
      "====> Epoch: 10 Average train loss: 3.6920787349\n",
      "====> Epoch: 10 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 10 Average eval loss: 0.9457392097\n",
      "====> Epoch: 11 Average train loss: 3.7854309277\n",
      "====> Epoch: 11 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 11 Average eval loss: 0.9298668504\n",
      "====> Epoch: 12 Average train loss: 3.6604434217\n",
      "====> Epoch: 12 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 12 Average eval loss: 0.9547272921\n",
      "====> Epoch: 13 Average train loss: 3.5920170646\n",
      "====> Epoch: 13 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 13 Average eval loss: 0.8970072865\n",
      "====> Epoch: 14 Average train loss: 3.2421704201\n",
      "====> Epoch: 14 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 14 Average eval loss: 0.9199703932\n",
      "====> Epoch: 15 Average train loss: 3.2173577232\n",
      "====> Epoch: 15 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 15 Average eval loss: 1.3198505640\n",
      "====> Epoch: 16 Average train loss: 2.8874870166\n",
      "====> Epoch: 16 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 16 Average eval loss: 0.9490736127\n",
      "====> Epoch: 17 Average train loss: 2.8203960554\n",
      "====> Epoch: 17 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 17 Average eval loss: 1.0836902857\n",
      "====> Epoch: 18 Average train loss: 2.5156813594\n",
      "====> Epoch: 18 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 18 Average eval loss: 1.0708329678\n",
      "====> Epoch: 19 Average train loss: 2.5557727373\n",
      "====> Epoch: 19 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 19 Average eval loss: 1.1592842340\n",
      "====> Epoch: 20 Average train loss: 2.5555724919\n",
      "====> Epoch: 20 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 20 Average eval loss: 1.2246898413\n",
      "====> Epoch: 21 Average train loss: 2.4136012296\n",
      "====> Epoch: 21 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 21 Average eval loss: 1.1109718084\n",
      "====> Epoch: 22 Average train loss: 2.4041373553\n",
      "====> Epoch: 22 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 22 Average eval loss: 1.1471782923\n",
      "====> Epoch: 23 Average train loss: 2.2516850744\n",
      "====> Epoch: 23 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 23 Average eval loss: 1.0372991562\n",
      "====> Epoch: 24 Average train loss: 2.0842046881\n",
      "====> Epoch: 24 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 24 Average eval loss: 1.2345759869\n",
      "====> Epoch: 25 Average train loss: 1.9330550799\n",
      "====> Epoch: 25 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 25 Average eval loss: 1.5456020832\n",
      "====> Epoch: 26 Average train loss: 2.0991619876\n",
      "====> Epoch: 26 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 26 Average eval loss: 1.4298224449\n",
      "====> Epoch: 27 Average train loss: 1.7919029732\n",
      "====> Epoch: 27 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 27 Average eval loss: 1.5113260746\n",
      "====> Epoch: 28 Average train loss: 1.9651828113\n",
      "====> Epoch: 28 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 28 Average eval loss: 1.1275641918\n",
      "====> Epoch: 29 Average train loss: 1.8560784464\n",
      "====> Epoch: 29 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 29 Average eval loss: 1.4384497404\n",
      "====> Epoch: 30 Average train loss: 1.7876760059\n",
      "====> Epoch: 30 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 30 Average eval loss: 1.5597774982\n",
      "====> Epoch: 31 Average train loss: 1.8713330522\n",
      "====> Epoch: 31 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 31 Average eval loss: 1.2007228136\n",
      "====> Epoch: 32 Average train loss: 1.6293687309\n",
      "====> Epoch: 32 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 32 Average eval loss: 1.2175183296\n",
      "====> Epoch: 33 Average train loss: 1.6219614832\n",
      "====> Epoch: 33 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 33 Average eval loss: 1.3298072815\n",
      "====> Epoch: 34 Average train loss: 1.5380622305\n",
      "====> Epoch: 34 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 34 Average eval loss: 1.2349017859\n",
      "====> Epoch: 35 Average train loss: 1.5082317321\n",
      "====> Epoch: 35 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 35 Average eval loss: 1.3717118502\n",
      "====> Epoch: 36 Average train loss: 1.4418312768\n",
      "====> Epoch: 36 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 36 Average eval loss: 1.2193500996\n",
      "====> Epoch: 37 Average train loss: 1.4663098611\n",
      "====> Epoch: 37 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 37 Average eval loss: 1.2219759226\n",
      "====> Epoch: 38 Average train loss: 1.4248953060\n",
      "====> Epoch: 38 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 38 Average eval loss: 1.2719172239\n",
      "====> Epoch: 39 Average train loss: 1.3565536462\n",
      "====> Epoch: 39 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 39 Average eval loss: 1.5122150183\n",
      "====> Epoch: 40 Average train loss: 1.4249139737\n",
      "====> Epoch: 40 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 40 Average eval loss: 1.4434616566\n",
      "====> Epoch: 41 Average train loss: 1.3781796100\n",
      "====> Epoch: 41 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 41 Average eval loss: 1.8324030638\n",
      "====> Epoch: 42 Average train loss: 1.2868680730\n",
      "====> Epoch: 42 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 42 Average eval loss: 1.1210606098\n",
      "====> Epoch: 43 Average train loss: 1.3011345302\n",
      "====> Epoch: 43 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 43 Average eval loss: 1.1130316257\n",
      "====> Epoch: 44 Average train loss: 1.2170341019\n",
      "====> Epoch: 44 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 44 Average eval loss: 1.1998367310\n",
      "====> Epoch: 45 Average train loss: 1.1996281400\n",
      "====> Epoch: 45 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 45 Average eval loss: 1.0245443583\n",
      "====> Epoch: 46 Average train loss: 1.1217999650\n",
      "====> Epoch: 46 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 46 Average eval loss: 1.7415983677\n",
      "====> Epoch: 47 Average train loss: 1.0811770611\n",
      "====> Epoch: 47 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 47 Average eval loss: 1.2150161266\n",
      "====> Epoch: 48 Average train loss: 1.0547797351\n",
      "====> Epoch: 48 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 48 Average eval loss: 1.5855644941\n",
      "====> Epoch: 49 Average train loss: 1.0068044946\n",
      "====> Epoch: 49 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 49 Average eval loss: 1.4993221760\n",
      "====> Epoch: 50 Average train loss: 1.0019895593\n",
      "====> Epoch: 50 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 50 Average eval loss: 1.6240544319\n",
      "====> Epoch: 51 Average train loss: 1.0368933472\n",
      "====> Epoch: 51 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 51 Average eval loss: 1.4461989403\n",
      "====> Epoch: 52 Average train loss: 0.8983520627\n",
      "====> Epoch: 52 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 52 Average eval loss: 1.5713717937\n",
      "====> Epoch: 53 Average train loss: 0.9380191635\n",
      "====> Epoch: 53 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 53 Average eval loss: 1.3987238407\n",
      "====> Epoch: 54 Average train loss: 0.8763435110\n",
      "====> Epoch: 54 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 54 Average eval loss: 1.3434422016\n",
      "====> Epoch: 55 Average train loss: 0.9455045595\n",
      "====> Epoch: 55 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 55 Average eval loss: 1.2802484035\n",
      "====> Epoch: 56 Average train loss: 0.8919307439\n",
      "====> Epoch: 56 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 56 Average eval loss: 1.3190159798\n",
      "====> Epoch: 57 Average train loss: 0.8277752707\n",
      "====> Epoch: 57 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 57 Average eval loss: 1.3862948418\n",
      "====> Epoch: 58 Average train loss: 0.8196939510\n",
      "====> Epoch: 58 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 58 Average eval loss: 1.4826898575\n",
      "====> Epoch: 59 Average train loss: 0.7999156346\n",
      "====> Epoch: 59 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 59 Average eval loss: 0.9070752859\n",
      "====> Epoch: 60 Average train loss: 0.8236659479\n",
      "====> Epoch: 60 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 60 Average eval loss: 0.8073810935\n",
      "====> Epoch: 61 Average train loss: 0.7344649067\n",
      "====> Epoch: 61 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 61 Average eval loss: 1.1888635159\n",
      "====> Epoch: 62 Average train loss: 0.7525946703\n",
      "====> Epoch: 62 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 62 Average eval loss: 1.1490999460\n",
      "====> Epoch: 63 Average train loss: 0.6898133683\n",
      "====> Epoch: 63 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 63 Average eval loss: 1.1752223969\n",
      "====> Epoch: 64 Average train loss: 0.7850742519\n",
      "====> Epoch: 64 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 64 Average eval loss: 0.9842191339\n",
      "====> Epoch: 65 Average train loss: 0.7242740102\n",
      "====> Epoch: 65 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 65 Average eval loss: 1.0254245996\n",
      "====> Epoch: 66 Average train loss: 0.6761075816\n",
      "====> Epoch: 66 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 66 Average eval loss: 1.2099167109\n",
      "====> Epoch: 67 Average train loss: 0.6367758997\n",
      "====> Epoch: 67 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 67 Average eval loss: 1.2053718567\n",
      "====> Epoch: 68 Average train loss: 0.6170607243\n",
      "====> Epoch: 68 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 68 Average eval loss: 0.8671667576\n",
      "====> Epoch: 69 Average train loss: 0.5963859689\n",
      "====> Epoch: 69 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 69 Average eval loss: 1.2411891222\n",
      "====> Epoch: 70 Average train loss: 0.6337938367\n",
      "====> Epoch: 70 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 70 Average eval loss: 1.2183979750\n",
      "====> Epoch: 71 Average train loss: 0.5964553656\n",
      "====> Epoch: 71 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 71 Average eval loss: 0.8392212391\n",
      "====> Epoch: 72 Average train loss: 0.5945443964\n",
      "====> Epoch: 72 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 72 Average eval loss: 0.8420170546\n",
      "====> Epoch: 73 Average train loss: 0.6161346217\n",
      "====> Epoch: 73 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 73 Average eval loss: 1.1167228222\n",
      "====> Epoch: 74 Average train loss: 0.5547467283\n",
      "====> Epoch: 74 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 74 Average eval loss: 1.0921068192\n",
      "====> Epoch: 75 Average train loss: 0.5986040351\n",
      "====> Epoch: 75 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 75 Average eval loss: 1.1753134727\n",
      "====> Epoch: 76 Average train loss: 0.5221676920\n",
      "====> Epoch: 76 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 76 Average eval loss: 1.2862017155\n",
      "====> Epoch: 77 Average train loss: 0.5365002614\n",
      "====> Epoch: 77 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 77 Average eval loss: 1.2101435661\n",
      "====> Epoch: 78 Average train loss: 0.5544773816\n",
      "====> Epoch: 78 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 78 Average eval loss: 1.0657956600\n",
      "====> Epoch: 79 Average train loss: 0.5280152267\n",
      "====> Epoch: 79 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 79 Average eval loss: 1.0810455084\n",
      "====> Epoch: 80 Average train loss: 0.5017302350\n",
      "====> Epoch: 80 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 80 Average eval loss: 1.1758773327\n",
      "====> Epoch: 81 Average train loss: 0.5432959777\n",
      "====> Epoch: 81 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 81 Average eval loss: 1.0342836380\n",
      "====> Epoch: 82 Average train loss: 0.4931254895\n",
      "====> Epoch: 82 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 82 Average eval loss: 1.1993443966\n",
      "====> Epoch: 83 Average train loss: 0.4616161790\n",
      "====> Epoch: 83 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 83 Average eval loss: 1.0982890129\n",
      "====> Epoch: 84 Average train loss: 0.4263871567\n",
      "====> Epoch: 84 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 84 Average eval loss: 0.9590767622\n",
      "====> Epoch: 85 Average train loss: 0.4605371045\n",
      "====> Epoch: 85 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 85 Average eval loss: 0.8266022205\n",
      "====> Epoch: 86 Average train loss: 0.4414188980\n",
      "====> Epoch: 86 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 86 Average eval loss: 0.7797785997\n",
      "====> Epoch: 87 Average train loss: 0.4492366501\n",
      "====> Epoch: 87 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 87 Average eval loss: 1.1956996918\n",
      "====> Epoch: 88 Average train loss: 0.4668984816\n",
      "====> Epoch: 88 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 88 Average eval loss: 1.2810775042\n",
      "====> Epoch: 89 Average train loss: 0.3937037238\n",
      "====> Epoch: 89 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 89 Average eval loss: 0.8747644424\n",
      "====> Epoch: 90 Average train loss: 0.3741598293\n",
      "====> Epoch: 90 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 90 Average eval loss: 1.1498905420\n",
      "====> Epoch: 91 Average train loss: 0.3698684062\n",
      "====> Epoch: 91 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 91 Average eval loss: 1.0694271326\n",
      "====> Epoch: 92 Average train loss: 0.3706172249\n",
      "====> Epoch: 92 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 92 Average eval loss: 0.8239927292\n",
      "====> Epoch: 93 Average train loss: 0.3609531381\n",
      "====> Epoch: 93 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 93 Average eval loss: 0.9747790694\n",
      "====> Epoch: 94 Average train loss: 0.3475351775\n",
      "====> Epoch: 94 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 94 Average eval loss: 0.8147745132\n",
      "====> Epoch: 95 Average train loss: 0.3945151381\n",
      "====> Epoch: 95 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 95 Average eval loss: 0.9535062313\n",
      "====> Epoch: 96 Average train loss: 0.3568431897\n",
      "====> Epoch: 96 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 96 Average eval loss: 1.1695355177\n",
      "====> Epoch: 97 Average train loss: 0.3869960063\n",
      "====> Epoch: 97 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 97 Average eval loss: 1.2999937534\n",
      "====> Epoch: 98 Average train loss: 0.3546322124\n",
      "====> Epoch: 98 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 98 Average eval loss: 1.0057232380\n",
      "====> Epoch: 99 Average train loss: 0.3504291757\n",
      "====> Epoch: 99 Average L0 reg loss: 0.0000000000\n",
      "====> Epoch: 99 Average eval loss: 0.8492866158\n",
      "Best testing error sparse FCNN is 0.7797785997390747 and it was found at epoch 86\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:52:37.251241Z",
     "start_time": "2024-05-22T15:51:48.241318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "degree = 3\n",
    "reg_coefficient = 0.01\n",
    "l0sindy_model = L0SINDy_reward(input_dim=obs_dim+act_dim, output_dim=1, degree=degree, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    l0sindy_model = l0sindy_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': l0sindy_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_l0sindy = train_eval_reward_model(l0sindy_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error L0 SINDy is {} and it was found at epoch {}\".format(metrics_l0sindy[2], metrics_l0sindy[3]))\n",
    "\n",
    "l0sindy_model.print_equations()"
   ],
   "id": "d8761a32de0032cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy polynomial of order  3\n",
      "with 35 coefficients\n",
      "['1' 'x0' 'x1' 'x2' 'x3' 'x0^2' 'x0 x1' 'x0 x2' 'x0 x3' 'x1^2' 'x1 x2'\n",
      " 'x1 x3' 'x2^2' 'x2 x3' 'x3^2' 'x0^3' 'x0^2 x1' 'x0^2 x2' 'x0^2 x3'\n",
      " 'x0 x1^2' 'x0 x1 x2' 'x0 x1 x3' 'x0 x2^2' 'x0 x2 x3' 'x0 x3^2' 'x1^3'\n",
      " 'x1^2 x2' 'x1^2 x3' 'x1 x2^2' 'x1 x2 x3' 'x1 x3^2' 'x2^3' 'x2^2 x3'\n",
      " 'x2 x3^2' 'x3^3']\n",
      "L0Dense(35 -> 1, droprate_init=0.5, lamba=0.01, temperature=0.6666666666666666, weight_decay=0.0, local_rep=False, bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolo/Documents/Sparsifying-Parametric-Models-with-L0/l0_layer.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.weights, mode='fan_out')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average train loss: 860.1311251191\n",
      "====> Epoch: 0 Average L0 reg loss: 0.2908181244\n",
      "====> Epoch: 0 Average eval loss: 191.3743743896\n",
      "====> Epoch: 1 Average train loss: 220.3858759361\n",
      "====> Epoch: 1 Average L0 reg loss: 0.2911279030\n",
      "====> Epoch: 1 Average eval loss: 28.2232437134\n",
      "====> Epoch: 2 Average train loss: 42.9168661465\n",
      "====> Epoch: 2 Average L0 reg loss: 0.2911557696\n",
      "====> Epoch: 2 Average eval loss: 4.3544363976\n",
      "====> Epoch: 3 Average train loss: 14.5236438739\n",
      "====> Epoch: 3 Average L0 reg loss: 0.2908907707\n",
      "====> Epoch: 3 Average eval loss: 4.2804379463\n",
      "====> Epoch: 4 Average train loss: 10.4002836793\n",
      "====> Epoch: 4 Average L0 reg loss: 0.2905083405\n",
      "====> Epoch: 4 Average eval loss: 3.8734283447\n",
      "====> Epoch: 5 Average train loss: 9.1733456146\n",
      "====> Epoch: 5 Average L0 reg loss: 0.2900795895\n",
      "====> Epoch: 5 Average eval loss: 3.0318460464\n",
      "====> Epoch: 6 Average train loss: 8.0199446121\n",
      "====> Epoch: 6 Average L0 reg loss: 0.2894383367\n",
      "====> Epoch: 6 Average eval loss: 2.5213730335\n",
      "====> Epoch: 7 Average train loss: 6.6857077456\n",
      "====> Epoch: 7 Average L0 reg loss: 0.2884596897\n",
      "====> Epoch: 7 Average eval loss: 1.8124190569\n",
      "====> Epoch: 8 Average train loss: 5.6795132463\n",
      "====> Epoch: 8 Average L0 reg loss: 0.2870514562\n",
      "====> Epoch: 8 Average eval loss: 1.6561925411\n",
      "====> Epoch: 9 Average train loss: 5.3100889222\n",
      "====> Epoch: 9 Average L0 reg loss: 0.2852459191\n",
      "====> Epoch: 9 Average eval loss: 1.3295689821\n",
      "====> Epoch: 10 Average train loss: 4.8032305686\n",
      "====> Epoch: 10 Average L0 reg loss: 0.2829727126\n",
      "====> Epoch: 10 Average eval loss: 1.0986212492\n",
      "====> Epoch: 11 Average train loss: 4.1767610300\n",
      "====> Epoch: 11 Average L0 reg loss: 0.2801173101\n",
      "====> Epoch: 11 Average eval loss: 0.9140255451\n",
      "====> Epoch: 12 Average train loss: 3.7865262493\n",
      "====> Epoch: 12 Average L0 reg loss: 0.2766723497\n",
      "====> Epoch: 12 Average eval loss: 0.8469061255\n",
      "====> Epoch: 13 Average train loss: 3.6077065774\n",
      "====> Epoch: 13 Average L0 reg loss: 0.2725350692\n",
      "====> Epoch: 13 Average eval loss: 0.6738052368\n",
      "====> Epoch: 14 Average train loss: 3.1353967679\n",
      "====> Epoch: 14 Average L0 reg loss: 0.2676933768\n",
      "====> Epoch: 14 Average eval loss: 0.6176620126\n",
      "====> Epoch: 15 Average train loss: 3.1604153433\n",
      "====> Epoch: 15 Average L0 reg loss: 0.2621379474\n",
      "====> Epoch: 15 Average eval loss: 0.5808318853\n",
      "====> Epoch: 16 Average train loss: 2.9451540445\n",
      "====> Epoch: 16 Average L0 reg loss: 0.2558826326\n",
      "====> Epoch: 16 Average eval loss: 0.5742275119\n",
      "====> Epoch: 17 Average train loss: 2.7083100245\n",
      "====> Epoch: 17 Average L0 reg loss: 0.2489707773\n",
      "====> Epoch: 17 Average eval loss: 0.5602090955\n",
      "====> Epoch: 18 Average train loss: 2.3697866958\n",
      "====> Epoch: 18 Average L0 reg loss: 0.2415679454\n",
      "====> Epoch: 18 Average eval loss: 0.5028384328\n",
      "====> Epoch: 19 Average train loss: 2.1469458722\n",
      "====> Epoch: 19 Average L0 reg loss: 0.2338587957\n",
      "====> Epoch: 19 Average eval loss: 0.4959280193\n",
      "====> Epoch: 20 Average train loss: 2.0662858622\n",
      "====> Epoch: 20 Average L0 reg loss: 0.2260568535\n",
      "====> Epoch: 20 Average eval loss: 0.4309562445\n",
      "====> Epoch: 21 Average train loss: 1.8310062190\n",
      "====> Epoch: 21 Average L0 reg loss: 0.2183646154\n",
      "====> Epoch: 21 Average eval loss: 0.4729129672\n",
      "====> Epoch: 22 Average train loss: 2.0077817158\n",
      "====> Epoch: 22 Average L0 reg loss: 0.2108684994\n",
      "====> Epoch: 22 Average eval loss: 0.4656560421\n",
      "====> Epoch: 23 Average train loss: 1.7272639841\n",
      "====> Epoch: 23 Average L0 reg loss: 0.2037217963\n",
      "====> Epoch: 23 Average eval loss: 0.4284450114\n",
      "====> Epoch: 24 Average train loss: 1.6163701167\n",
      "====> Epoch: 24 Average L0 reg loss: 0.1969284609\n",
      "====> Epoch: 24 Average eval loss: 0.5250095725\n",
      "====> Epoch: 25 Average train loss: 1.4734715588\n",
      "====> Epoch: 25 Average L0 reg loss: 0.1904782019\n",
      "====> Epoch: 25 Average eval loss: 0.4835886657\n",
      "====> Epoch: 26 Average train loss: 1.4201088785\n",
      "====> Epoch: 26 Average L0 reg loss: 0.1844800594\n",
      "====> Epoch: 26 Average eval loss: 0.4413147271\n",
      "====> Epoch: 27 Average train loss: 1.2384954576\n",
      "====> Epoch: 27 Average L0 reg loss: 0.1788574222\n",
      "====> Epoch: 27 Average eval loss: 0.4652553201\n",
      "====> Epoch: 28 Average train loss: 1.2740245955\n",
      "====> Epoch: 28 Average L0 reg loss: 0.1735510479\n",
      "====> Epoch: 28 Average eval loss: 0.4681427479\n",
      "====> Epoch: 29 Average train loss: 1.2497462631\n",
      "====> Epoch: 29 Average L0 reg loss: 0.1687111084\n",
      "====> Epoch: 29 Average eval loss: 0.4950564206\n",
      "====> Epoch: 30 Average train loss: 1.1097338720\n",
      "====> Epoch: 30 Average L0 reg loss: 0.1641685201\n",
      "====> Epoch: 30 Average eval loss: 0.4077433944\n",
      "====> Epoch: 31 Average train loss: 1.0775883054\n",
      "====> Epoch: 31 Average L0 reg loss: 0.1599450349\n",
      "====> Epoch: 31 Average eval loss: 0.3501192331\n",
      "====> Epoch: 32 Average train loss: 0.8878925837\n",
      "====> Epoch: 32 Average L0 reg loss: 0.1559586993\n",
      "====> Epoch: 32 Average eval loss: 0.3118979037\n",
      "====> Epoch: 33 Average train loss: 1.0008183744\n",
      "====> Epoch: 33 Average L0 reg loss: 0.1520534445\n",
      "====> Epoch: 33 Average eval loss: 0.3163371384\n",
      "====> Epoch: 34 Average train loss: 0.9627084350\n",
      "====> Epoch: 34 Average L0 reg loss: 0.1482728778\n",
      "====> Epoch: 34 Average eval loss: 0.2964716852\n",
      "====> Epoch: 35 Average train loss: 1.0432416955\n",
      "====> Epoch: 35 Average L0 reg loss: 0.1446793866\n",
      "====> Epoch: 35 Average eval loss: 0.3209217191\n",
      "====> Epoch: 36 Average train loss: 0.8399822066\n",
      "====> Epoch: 36 Average L0 reg loss: 0.1413993758\n",
      "====> Epoch: 36 Average eval loss: 0.3433061242\n",
      "====> Epoch: 37 Average train loss: 0.7288241375\n",
      "====> Epoch: 37 Average L0 reg loss: 0.1382086426\n",
      "====> Epoch: 37 Average eval loss: 0.2445264757\n",
      "====> Epoch: 38 Average train loss: 0.7330422979\n",
      "====> Epoch: 38 Average L0 reg loss: 0.1350064074\n",
      "====> Epoch: 38 Average eval loss: 0.2313402295\n",
      "====> Epoch: 39 Average train loss: 0.7631211243\n",
      "====> Epoch: 39 Average L0 reg loss: 0.1318332289\n",
      "====> Epoch: 39 Average eval loss: 0.2484590709\n",
      "====> Epoch: 40 Average train loss: 0.6679352877\n",
      "====> Epoch: 40 Average L0 reg loss: 0.1288484657\n",
      "====> Epoch: 40 Average eval loss: 0.2484685034\n",
      "====> Epoch: 41 Average train loss: 0.6961807869\n",
      "====> Epoch: 41 Average L0 reg loss: 0.1260059651\n",
      "====> Epoch: 41 Average eval loss: 0.2569911182\n",
      "====> Epoch: 42 Average train loss: 0.6358637973\n",
      "====> Epoch: 42 Average L0 reg loss: 0.1232767978\n",
      "====> Epoch: 42 Average eval loss: 0.2526398003\n",
      "====> Epoch: 43 Average train loss: 0.6019848375\n",
      "====> Epoch: 43 Average L0 reg loss: 0.1207642140\n",
      "====> Epoch: 43 Average eval loss: 0.1867737025\n",
      "====> Epoch: 44 Average train loss: 0.5498366873\n",
      "====> Epoch: 44 Average L0 reg loss: 0.1184575337\n",
      "====> Epoch: 44 Average eval loss: 0.1717070043\n",
      "====> Epoch: 45 Average train loss: 0.4836937127\n",
      "====> Epoch: 45 Average L0 reg loss: 0.1163013629\n",
      "====> Epoch: 45 Average eval loss: 0.1779419780\n",
      "====> Epoch: 46 Average train loss: 0.5546664912\n",
      "====> Epoch: 46 Average L0 reg loss: 0.1143915525\n",
      "====> Epoch: 46 Average eval loss: 0.1810371429\n",
      "====> Epoch: 47 Average train loss: 0.4328441467\n",
      "====> Epoch: 47 Average L0 reg loss: 0.1126823025\n",
      "====> Epoch: 47 Average eval loss: 0.1754314750\n",
      "====> Epoch: 48 Average train loss: 0.4630725576\n",
      "====> Epoch: 48 Average L0 reg loss: 0.1111658287\n",
      "====> Epoch: 48 Average eval loss: 0.1507905722\n",
      "====> Epoch: 49 Average train loss: 0.4001962422\n",
      "====> Epoch: 49 Average L0 reg loss: 0.1097746739\n",
      "====> Epoch: 49 Average eval loss: 0.1446280926\n",
      "Best testing error L0 SINDy is 0.14462809264659882 and it was found at epoch 49\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# creating the plots\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Training and Evaluation Metrics')\n",
    "\n",
    "data_train = {'FCNN (train)': metrics_fcnn[0], 'SparseFCNN (train)': metrics_sparsefcnn[0], 'L0SINDy (train)': metrics_l0sindy[0]}\n",
    "methods_train = list(data_train.keys())\n",
    "values_train = list(data_train.values())\n",
    "\n",
    "# creating the bar plot\n",
    "ax1.bar(methods_train, values_train, color='maroon', width=0.4)\n",
    "\n",
    "data_eval = {'FCNN (eval)': metrics_fcnn[1], 'SparseFCNN (eval)': metrics_sparsefcnn[1], 'L0SINDy (eval)': metrics_l0sindy[0]}\n",
    "methods_eval = list(data_eval.keys())\n",
    "values_eval = list(data_eval.values())\n",
    "\n",
    "ax2.bar(methods_eval, values_eval, color='blue', width=0.4)\n",
    "\n",
    "save_dir = \"figures\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "fig.savefig('figures/LearningReward.png', dpi=300)"
   ],
   "id": "3f52e2a18f31e291"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
