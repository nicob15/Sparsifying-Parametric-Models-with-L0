{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Learning Sparse Dynamical Models\n",
    "\n",
    "We consider the case of learning the dynamics of a pendulum. In particular, we aim to learn the transition function $T:\\mathcal{S}\\times \\mathcal{A}\\rightarrow \\mathcal{S}$, predicting the next state $\\hat{\\mathbf{s}}_{t+1}$ from the current state $\\mathbf{s}_t$ and action $\\mathbf{a}_t$: $$\\hat{\\mathbf{s}}_{t+1}=T(\\mathbf{s}_t, \\mathbf{a}_t).$$ We will approximate $T(\\mathbf{s}_t, \\mathbf{a}_t)$ using:\n",
    "* a fully-connected neural network (fcnn_model),\n",
    "* a fully-connected neural network sparsified by the L$_0$ regularization (sparsefcnn_model), and\n",
    "* a SINDy-like architecture again sparsified by the L$_0$ regularization (l0sindy_model)."
   ],
   "id": "7b7ca3e2b76dfbb6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T09:37:45.443241Z",
     "start_time": "2024-06-19T09:37:44.662323Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "from utils.replay_buffer import ReplayBuffer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds\n",
    "seed = 23524\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We first create a training set composed of 1000 episodes of 200 steps each. The actions are sampled from a random policy.",
   "id": "8ddbdef861816cc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "render = False\n",
    "if render:\n",
    "    env = gym.make('Pendulum-v1', g=9.81, render_mode=\"human\")\n",
    "else:\n",
    "    env = gym.make('Pendulum-v1', g=9.81)\n",
    "max_episodes = 1000\n",
    "max_steps = 200\n",
    "\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "training_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "# create training set\n",
    "for episode in range(max_episodes):\n",
    "    observation, _ = env.reset()\n",
    "    for steps in range(max_steps+1):\n",
    "        action = env.action_space.sample()\n",
    "        next_observation, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "        training_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the training set\")"
   ],
   "id": "f30d49f053f6de6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Secondly, we create the test set that we will use to evaluate the models.",
   "id": "8273bd38694c4609"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create test set\n",
    "max_episodes_test = 100\n",
    "buf_dim = int(max_episodes*max_steps)\n",
    "\n",
    "testing_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=buf_dim)\n",
    "\n",
    "# create training set\n",
    "for episode in range(max_episodes_test):\n",
    "    observation, _ = env.reset()\n",
    "    for steps in range(max_steps + 1):\n",
    "        action = env.action_space.sample()\n",
    "        next_observation, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "        testing_buffer.store(observation, action, reward, next_observation, done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            done = False\n",
    "            break\n",
    "\n",
    "print(\"Finished creating the test set\")"
   ],
   "id": "5c45b1ee713bfd84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After creating train and test set, we are now ready to train the three models. We utilize the same learning rate, batch size, and number of traning epochs.",
   "id": "1dd2318732f7de44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:41:28.987536Z",
     "start_time": "2024-06-19T10:41:28.984628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.models import FCNN, SparseFCNN, L0SINDy_dynamics\n",
    "from utils.trainer import train_eval_dynamics_model\n",
    "import torch\n",
    "\n",
    "# number of hidden units used by the fcnn_model and the sparsefcnn_model\n",
    "h_dim = 128\n",
    "\n",
    "# shared hyperparameter of the experiment\n",
    "lr = 3e-4\n",
    "batch_size = 256\n",
    "num_epochs = 500"
   ],
   "id": "5b9d333e476e4824",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train and evaluate the fcnn_model.",
   "id": "74aea84006ae75c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fcnn_model = FCNN(input_dim=obs_dim+act_dim, output_dim=obs_dim, h_dim=h_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fcnn_model = fcnn_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': fcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_fcnn = train_eval_dynamics_model(fcnn_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs)\n",
    "print(\"Best testing error FCNN is {} and it was found at epoch {}\".format(metrics_fcnn[2], metrics_fcnn[3]))"
   ],
   "id": "2cac37c5b681ba1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train and evaluate the sparsefcnn_model.",
   "id": "9cfbed8187fd361a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reg_coefficient = 0.0001\n",
    "sparsefcnn_model = SparseFCNN(input_dim=obs_dim+act_dim, output_dim=obs_dim, h_dim=h_dim, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sparsefcnn_model = sparsefcnn_model.cuda()\n",
    "\n",
    "optimizer_sparsefcnn = torch.optim.Adam([\n",
    "    {'params': sparsefcnn_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_sparsefcnn = train_eval_dynamics_model(sparsefcnn_model, optimizer_sparsefcnn, training_buffer, testing_buffer,\n",
    "                                               batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error sparse FCNN is {} and it was found at epoch {}\".format(metrics_sparsefcnn[2], metrics_sparsefcnn[3]))"
   ],
   "id": "5f6094f05663b753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train and evaluate the l0sindy_model.",
   "id": "e73746a15dbf55df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# degree of the polynomial features\n",
    "degree = 3\n",
    "\n",
    "reg_coefficient = 0.0005\n",
    "l0sindy_model = L0SINDy_dynamics(input_dim=obs_dim+act_dim, output_dim=obs_dim, degree=degree, lambda_coeff=reg_coefficient)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    l0sindy_model = l0sindy_model.cuda()\n",
    "\n",
    "optimizer_fcnn = torch.optim.Adam([\n",
    "    {'params': l0sindy_model.parameters()},\n",
    "], lr=lr, weight_decay=0.0)\n",
    "\n",
    "metrics_l0sindy = train_eval_dynamics_model(l0sindy_model, optimizer_fcnn, training_buffer, testing_buffer, batch_size, num_epochs, l0=True)\n",
    "print(\"Best testing error L0 SINDy is {} and it was found at epoch {}\".format(metrics_l0sindy[2], metrics_l0sindy[3]))\n",
    "\n",
    "# print the close-form equation of the model. Great for interpretability!!!\n",
    "l0sindy_model.print_equations()"
   ],
   "id": "94717fb5ef5019b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eventually, we plot the mean-squared error between the predictions and the ground-truth over the training and test set.",
   "id": "90695781b7ab4e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# creating the plots\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Training and Evaluation Metrics')\n",
    "\n",
    "data_train = {'FCNN': metrics_fcnn[0], 'SparseFCNN': metrics_sparsefcnn[0], 'L0SINDy': metrics_l0sindy[0]}\n",
    "methods_train = list(data_train.keys())\n",
    "values_train = list(data_train.values())\n",
    "\n",
    "# creating the bar plot\n",
    "ax1.bar(methods_train, values_train, color='maroon', width=0.4)\n",
    "\n",
    "data_eval = {'FCNN': metrics_fcnn[2], 'SparseFCNN': metrics_sparsefcnn[2], 'L0SINDy': metrics_l0sindy[2]}\n",
    "methods_eval = list(data_eval.keys())\n",
    "values_eval = list(data_eval.values())\n",
    "\n",
    "ax2.bar(methods_eval, values_eval, color='blue', width=0.4)\n",
    "\n",
    "save_dir = \"figures\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "fig.savefig('figures/LearningDynamics.png', dpi=300)"
   ],
   "id": "5b52985fbff205cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
